import os
import time
import schedule
import threading
import functools
import random
import tempfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from openai import OpenAI
import ccxt
from ccxt.base.errors import NetworkError, RequestTimeout, ExchangeError
import pandas as pd
import numpy as np
from datetime import datetime, timezone
import json
import re
from dotenv import load_dotenv
import logging
from logging.handlers import RotatingFileHandler
from typing import Dict, Any, Optional, TypedDict, List
from typing import Tuple
import ssl  # FIXED: SSL 1 - æ·»åŠ  SSL æ”¯æŒ
import urllib3  # FIXED: SSL 2 - ç¦ç”¨è­¦å‘Š
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import requests  # FIXED: Data Fetch 2 - æ˜¾å¼å¯¼å…¥ requests

# FIXED: SSL 3 - ç¦ç”¨ urllib3 SSL è­¦å‘Šï¼ˆç”Ÿäº§ä¸­å¯é€‰ç§»é™¤ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Load environment variables from 1.env file (contains all API keys)
load_dotenv('1.env')

# FIXED: SSL 4 - è‡ªå®šä¹‰ SSL ä¸Šä¸‹æ–‡ï¼Œå¤„ç† EOF é”™è¯¯
def create_ssl_context():
    ctx = ssl.create_default_context()
    ctx.check_hostname = True  # ä¿æŒå®‰å…¨æ€§
    ctx.verify_mode = ssl.CERT_REQUIRED
    # è®¾ç½®æ›´å®½æ¾çš„åè®®ç‰ˆæœ¬ä»¥æé«˜å…¼å®¹æ€§
    ctx.minimum_version = ssl.TLSVersion.TLSv1_2
    return ctx

# Note: Custom modules commented out as they are not available in current environment
# from coindesk_websocket_indicators import CoinDeskWebSocketIndicatorProvider, CoinDeskIndicatorConfig
# from hyperliquid_websocket_backup import WebSocketIndicatorProvider as HyperliquidWebSocketProvider, IndicatorConfig as HyperliquidIndicatorConfig, HyperliquidBackupProvider
# from hyperliquid_market_data import HyperliquidMarketData

def setup_logging(log_file: str = 'trading_bot.log', level: str = 'INFO', enable_json: bool = False):
    """Elegant logging setup supporting categories and structured output"""
    # Clear existing handlers to avoid duplicates
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # Plain format (human-readable)
    plain_formatter = logging.Formatter(
        '%(asctime)s [%(threadName)-10s] %(name)-12s - %(levelname)-8s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # JSON format (optional, machine-readable)
    if enable_json:
        import json
        class JsonFormatter(logging.Formatter):
            def format(self, record):
                log_entry = {
                    'timestamp': self.formatTime(record),
                    'level': record.levelname,
                    'logger': record.name,
                    'thread': record.threadName,
                    'message': record.getMessage(),
                    'module': record.module,
                    'function': record.funcName,
                    'line': record.lineno
                }
                if record.exc_info:
                    log_entry['exception'] = self.formatException(record.exc_info)
                return json.dumps(log_entry, ensure_ascii=False)
        json_formatter = JsonFormatter()

    # Console handler (colored output)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(plain_formatter)
    console_handler.setLevel(level)

    # File handler (DEBUG level, rotating)
    file_handler = RotatingFileHandler(
        log_file, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
    )
    file_handler.setFormatter(json_formatter if enable_json else plain_formatter)
    file_handler.setLevel('DEBUG')

    # Root logger setup
    root_logger.setLevel('DEBUG')
    root_logger.addHandler(console_handler)
    root_logger.addHandler(file_handler)

    # Create category loggers
    loggers = {
        'trading': logging.getLogger('trading'),
        'api': logging.getLogger('api'), 
        'risk': logging.getLogger('risk'),
        'monitor': logging.getLogger('monitor'),
        'system': logging.getLogger('system')
    }

    # Suppress noisy third-party logs
    for noisy_logger in ['pandas', 'numpy', 'urllib3', 'requests', 'ccxt', 'httpx', 'httpcore', 'openai']:
        logging.getLogger(noisy_logger).setLevel('WARNING')
    
    # ç‰¹åˆ«æŠ‘åˆ¶OpenAIå’ŒHTTPç›¸å…³çš„è¯¦ç»†æ—¥å¿—
    logging.getLogger('openai._base_client').setLevel('WARNING')
    logging.getLogger('httpcore.connection').setLevel('WARNING')
    logging.getLogger('httpcore.http11').setLevel('WARNING')
    logging.getLogger('httpcore.proxy').setLevel('WARNING')
    logging.getLogger('schedule').setLevel('INFO')  # åªæ˜¾ç¤ºé‡è¦çš„è°ƒåº¦ä¿¡æ¯

    return loggers

# Initialize logging system
loggers = setup_logging('trading_bot.log', 'INFO')
logger = logging.getLogger(__name__)  # Maintain backward compatibility

@dataclass
class Config:
    """Configuration class for trading bot parameters."""
    symbol: str = 'ETH/USDC:USDC'
    amount: float = 0.01
    # Data source configuration
    data_source: str = 'websocket'  # 'websocket' or 'hyperliquid'
    use_websocket_indicators: bool = True  # Use WebSocket for real-time indicators
    leverage: int = 25
    timeframes: List[str] = None
    primary_timeframe: str = '15m'
    structure_confirm_timeframe: str = '1h'
    data_points: int = 200
    amplitude_lookback: int = 7
    activation_threshold: float = 0.0002  # 0.02% - é«˜æ•æ„Ÿåº¦æ¿€æ´»é˜ˆå€¼ï¼Œæ›´ç²¾ç¡®çš„ä»·æ ¼è§¦å‘
    min_balance_ratio: float = 0.95
    max_position_time: int = 86400
    risk_per_trade: float = 0.015  # 1.5% per trade loss at liquidation price
    slippage_buffer: float = 0.0005  # Reduced from 0.001 for aggressive execution (0.05%)
    volatility_threshold: float = 70
    order_timeout: int = 10
    heartbeat_interval: int = 60
    price_monitor_interval: int = 180  # 3åˆ†é’Ÿç›‘æ§é—´éš”ï¼Œæ›´åŠæ—¶æ•æ‰ä»·æ ¼å˜åŠ¨
    signals_file: str = 'signal_history.json'
    heartbeat_file: str = 'heartbeat.log'
    log_file: str = 'trading_bot.log'
    max_log_size: int = 10 * 1024 * 1024
    log_backup_count: int = 5
    deepseek_timeout: int = 30
    liquidity_priority: List[str] = None
    use_ema100: bool = True  # New: Toggle EMA100 usage
    ema100_priority: float = 0.7  # New: Multiplier for activation threshold
    min_fill_ratio: float = 0.95  # New: Minimum order fill ratio
    cache_ttl: int = 300  # New: Cache TTL in seconds
    rsi_neutral: float = 50  # New: Neutral RSI value
    rsi_min: float = 0  # New: RSI min clip
    rsi_max: float = 100  # New: RSI max clip
    simulation_mode: bool = False  # New: Simulation mode toggle (switched to live trading)
    backtest_file: Optional[str] = None  # Added for main()
    max_margin_usage: float = 0.60  # Maximum margin usage ratio
    fee_rate: float = 0.0002  # Taker fee
    maintenance_margin_rate: float = 0.005  # Hyperliquid default (approximate)
    primary_timeframe_weight: float = 2.0  # Weight for 15m structure
    rr_min_threshold: float = 2.0  # Min R:R for normal mode
    rr_aggressive_threshold: float = 2.5  # Min R:R for aggressive mode (15m+4h confirm)
    risk_aggressive: float = 0.02  # Aggressive risk if R:R high (reduced to 2%)
    temperature: float = 0.1  # FIXED: Medium 10 - Add temperature for DeepSeek
    # New: Max leverage per symbol
    max_leverage_per_symbol: Dict[str, int] = None
    # New: Risk control params
    max_daily_loss_pct: float = 0.12  # Max 12% daily loss
    max_drawdown_pct: float = 0.20  # Max 20% drawdown (increased)
    max_open_positions: int = 6  # Max 6 positions in isolated mode per symbol
    min_amount_usdc: float = 50.0  # Minimum position size in USDC (reduced to 50)
    dynamic_leverage: bool = True  # New: Enable dynamic leverage for high R:R
    # New: Multi-TF alignment and confirmation params
    higher_tf_bias_tf: str = '4h'  # Higher TF for bias (e.g., 4h or 1d)
    lower_tf_entry_tf: str = '15m'  # Lower TF for entry
    volume_confirmation_threshold: float = 1.2  # Volume > 1.2x MA
    max_zone_interactions: int = 1  # Max interactions for fresh zones
    fvg_stack_threshold: int = 2  # Min FVGs stacking for confirmation
    candle_pattern_weight: float = 1.5  # Weight for candle pattern confirmation
    # FIXED: Kill Zone 1 - æ·»åŠ  Kill Zone é…ç½®ï¼ˆå¯é€‰å…¨å¤©æµ‹è¯•ï¼‰
    kill_zone_start_utc: int = 8  # UTC å¼€å§‹å°æ—¶
    kill_zone_end_utc: int = 16   # UTC ç»“æŸå°æ—¶
    enable_kill_zone: bool = False  # æš‚æ—¶ç¦ç”¨Kill Zone
    # New: Level weights for FVG and OB
    level_weights: Dict[str, float] = None

    def __post_init__(self):
        if self.timeframes is None:
            self.timeframes = ['1d', '4h', '1h', '15m']
        if self.liquidity_priority is None:
            self.liquidity_priority = [
                # Daily level (highest priority)
                'monday_open', 'daily_open', 'prev_week_high', 'prev_week_low', 'daily_vwap', 'daily_fvg_bull_mid', 'daily_fvg_bear_mid',
                # 4H level (high priority)
                '4h_high', '4h_low', '4h_fvg_bull_mid', '4h_fvg_bear_mid', '4h_ob_bull', '4h_ob_bear', '4h_gap_up', '4h_gap_down',
                # 1H level (medium priority)
                'ema_21_1h', 'ema_55_1h', 'ema_100_1h', 'ema_200_1h', '1h_fvg_bull_mid', '1h_fvg_bear_mid', '1h_ob_bull', '1h_ob_bear',
                # 15m level (structure confirmation)
                '15m_structure_break', '15m_structure_reversal', '15m_liquidity_hunt', '15m_fvg_bull_mid', '15m_fvg_bear_mid', '15m_ob_bull', '15m_ob_bear'
            ]
        if self.max_leverage_per_symbol is None:
            self.max_leverage_per_symbol = {
                'HYPE/USDC:USDC': 10,  # HYPEæœ€å¤§æ æ†ï¼ˆäº¤æ˜“æ‰€é™åˆ¶ï¼‰
                'BTC/USDC:USDC': 40,
                'ETH/USDC:USDC': 25,
                'SOL/USDC': 20,
                'DOGE/USDC': 10,
                'BNB/USDC': 10,
                'XRP/USDC': 20,
                # Add more as needed
            }
        if self.level_weights is None:
            self.level_weights = {
                # Daily levels (highest)
                'monday_open': 4.0,
                'daily_open': 3.8,
                'prev_week_high': 3.5,
                'prev_week_low': 3.5,
                'daily_vwap': 3.2,
                'daily_fvg_bull_mid': 3.4,
                'daily_fvg_bear_mid': 3.4,
                'recent_10d_high': 3.0,
                'recent_10d_low': 3.0,
                'daily_ob_bull': 3.2,
                'daily_ob_bear': 3.2,
                # 4H levels (high)
                '4h_high': 2.5,
                '4h_low': 2.5,
                '4h_fvg_bull_mid': 2.2,
                '4h_fvg_bear_mid': 2.2,
                '4h_ob_bull': 2.5,
                '4h_ob_bear': 2.5,
                '4h_gap_up': 2.0,
                '4h_gap_down': 2.0,
                'ema_21_4h': 2.2,
                'ema_55_4h': 2.2,
                'ema_100_4h': 2.2,
                'ema_200_4h': 2.5,
                # 1H levels (medium)
                'ema_21_1h': 1.8,
                'ema_55_1h': 1.8,
                'ema_100_1h': 1.8,
                'ema_200_1h': 2.0,
                '1h_fvg_bull_mid': 1.6,
                '1h_fvg_bear_mid': 1.6,
                '1h_ob_bull': 1.8,
                '1h_ob_bear': 1.8,
                # 15m levels (entry)
                '15m_structure_break': 1.2,
                '15m_structure_reversal': 1.2,
                '15m_liquidity_hunt': 1.0,
                '15m_fvg_bull_mid': 1.2,
                '15m_fvg_bear_mid': 1.2,
                '15m_ob_bull': 1.4,
                '15m_ob_bear': 1.4,
            }
        self.validate()

    def validate(self):
        if not (1 <= self.leverage <= 125):
            raise ValueError(f"Leverage must be between 1-125, got: {self.leverage}")
        if not (0.001 <= self.risk_per_trade <= 0.05):
            raise ValueError(f"Risk per trade must be 0.1%-5%, got: {self.risk_per_trade*100:.1f}%")
        if self.amount < 0.01:
            raise ValueError(f"Amount must be >=0.01 BTC, got: {self.amount}")
        if not (0.0001 <= self.activation_threshold <= 0.05):
            raise ValueError(f"Activation threshold must be 0.01%-5%, got: {self.activation_threshold*100:.2f}%")
        if self.primary_timeframe not in self.timeframes:
            raise ValueError(f"Primary timeframe must be in timeframes, got: {self.primary_timeframe}")
        if not (0.1 <= self.max_margin_usage <= 0.95):
            raise ValueError(f"Max margin usage must be between 0.1-0.95, got: {self.max_margin_usage}")
        if not (0 < self.fee_rate < 0.01):
            raise ValueError(f"Fee rate must be between 0 and 1%, got: {self.fee_rate*100:.2f}%")
        if not (0 < self.maintenance_margin_rate < 0.1):
            raise ValueError(f"Maintenance margin rate must be between 0 and 10%, got: {self.maintenance_margin_rate*100:.1f}%")
        if not (1.0 <= self.primary_timeframe_weight <= 5.0):
            raise ValueError(f"Primary timeframe weight must be 1-5, got: {self.primary_timeframe_weight}")
        # FIXED: Medium 1 - Add all new fields validation
        if not (1.0 <= self.rr_min_threshold <= 5.0):
            raise ValueError(f"RR min threshold must be 1-5, got: {self.rr_min_threshold}")
        if not (1.0 <= self.rr_aggressive_threshold <= 5.0):
            raise ValueError(f"RR aggressive threshold must be 1-5, got: {self.rr_aggressive_threshold}")
        if not (0.005 <= self.risk_aggressive <= 0.10):
            raise ValueError(f"Aggressive risk must be 0.5%-10%, got: {self.risk_aggressive*100:.1f}%")
        if not (0 < self.temperature <= 1.0):
            raise ValueError(f"Temperature must be 0-1, got: {self.temperature}")
        if not (50.0 <= self.min_amount_usdc <= 1000.0):
            raise ValueError(f"Min amount USDC must be 50-1000, got: {self.min_amount_usdc}")
        # New: Validate max_leverage_per_symbol
        if self.symbol not in self.max_leverage_per_symbol:
            raise ValueError(f"Symbol {self.symbol} not in max_leverage_per_symbol")
        if not (0.01 <= self.max_daily_loss_pct <= 0.25):
            raise ValueError(f"Max daily loss must be 1%-25%, got: {self.max_daily_loss_pct*100:.1f}%")
        if not (0.05 <= self.max_drawdown_pct <= 0.2):
            raise ValueError(f"Max drawdown must be 5%-20%, got: {self.max_drawdown_pct*100:.1f}%")
        if self.max_open_positions < 1:
            raise ValueError(f"Max open positions must be >=1, got: {self.max_open_positions}")
        # New: Multi-TF and confirmation validation
        if self.higher_tf_bias_tf not in self.timeframes:
            raise ValueError(f"Higher TF bias must be in timeframes, got: {self.higher_tf_bias_tf}")
        if self.lower_tf_entry_tf not in self.timeframes:
            raise ValueError(f"Lower TF entry must be in timeframes, got: {self.lower_tf_entry_tf}")
        if not (1.0 <= self.volume_confirmation_threshold <= 2.0):
            raise ValueError(f"Volume confirmation threshold must be 1.0-2.0, got: {self.volume_confirmation_threshold}")
        if not (1 <= self.max_zone_interactions <= 3):
            raise ValueError(f"Max zone interactions must be 1-3, got: {self.max_zone_interactions}")
        if not (1 <= self.fvg_stack_threshold <= 5):
            raise ValueError(f"FVG stack threshold must be 1-5, got: {self.fvg_stack_threshold}")
        if not (1.0 <= self.candle_pattern_weight <= 2.0):
            raise ValueError(f"Candle pattern weight must be 1.0-2.0, got: {self.candle_pattern_weight}")
        # FIXED: Kill Zone 2 - éªŒè¯ Kill Zone
        if not (0 <= self.kill_zone_start_utc < 24 and 0 <= self.kill_zone_end_utc < 24):
            raise ValueError(f"Kill Zone hours must be 0-23, got start={self.kill_zone_start_utc}, end={self.kill_zone_end_utc}")

# å…¨å±€å˜é‡å£°æ˜ï¼Œä½†ä¸åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–
config = None
deepseek_client = None
exchange = None
system_logger = logging.getLogger('system')

def _display_startup_parameters(config):
    """æ˜¾ç¤ºå¯åŠ¨æ—¶çš„å…³é”®å‚æ•°å’Œé€»è¾‘æ¡ä»¶"""
    system_logger.info("=" * 80)
    system_logger.info("ğŸš€ DeepSeek AI äº¤æ˜“æœºå™¨äººå¯åŠ¨å‚æ•°æŠ¥å‘Š")
    system_logger.info("=" * 80)
    
    # åŸºç¡€äº¤æ˜“å‚æ•°
    system_logger.info("ğŸ“Š åŸºç¡€äº¤æ˜“å‚æ•°:")
    system_logger.info(f"   äº¤æ˜“å¯¹: {config.symbol}")
    system_logger.info(f"   æ æ†å€æ•°: {config.leverage}x")
    system_logger.info(f"   åŸºç¡€äº¤æ˜“é‡: {config.amount:.4f} ETH")
    system_logger.info(f"   è¿è¡Œæ¨¡å¼: {'ğŸ”´ å®ç›˜æ¨¡å¼' if not config.simulation_mode else 'ğŸŸ¡ æ¨¡æ‹Ÿæ¨¡å¼'}")
    
    # å…³é”®æ¿€æ´»å‚æ•°
    system_logger.info("ğŸ¯ ä»·æ ¼æ¿€æ´»å‚æ•°:")
    system_logger.info(f"   æ¿€æ´»é˜ˆå€¼: {config.activation_threshold*100:.3f}% (ä»·æ ¼æ¥è¿‘å…³é”®æ°´å¹³çš„è§¦å‘è·ç¦»)")
    system_logger.info(f"   ä¸»è¦æ—¶é—´æ¡†æ¶: {config.primary_timeframe}")
    system_logger.info(f"   ç¡®è®¤æ—¶é—´æ¡†æ¶: {config.structure_confirm_timeframe}")
    system_logger.info(f"   ç›‘æ§é—´éš”: {config.price_monitor_interval}ç§’")
    
    # Kill Zone è®¾ç½®
    system_logger.info("â° Kill Zone è®¾ç½®:")
    if config.enable_kill_zone:
        system_logger.info(f"   çŠ¶æ€: ğŸŸ¢ å¯ç”¨")
        system_logger.info(f"   äº¤æ˜“æ—¶é—´: UTC {config.kill_zone_start_utc}:00 - {config.kill_zone_end_utc}:00")
    else:
        system_logger.info(f"   çŠ¶æ€: ğŸ”´ ç¦ç”¨ (å…¨å¤©å€™äº¤æ˜“)")
    
    # é£é™©ç®¡ç†å‚æ•°
    system_logger.info("ğŸ›¡ï¸ é£é™©ç®¡ç†å‚æ•°:")
    system_logger.info(f"   æ¯ç¬”äº¤æ˜“é£é™©: {config.risk_per_trade*100:.1f}%")
    system_logger.info(f"   æœ€å¤§ä¿è¯é‡‘ä½¿ç”¨: {config.max_margin_usage*100:.0f}%")
    system_logger.info(f"   æœ€å¤§æ—¥äºæŸ: {config.max_daily_loss_pct*100:.0f}%")
    system_logger.info(f"   æœ€å¤§å›æ’¤: {config.max_drawdown_pct*100:.0f}%")
    system_logger.info(f"   æœ€å°æŒä»“é‡‘é¢: ${config.min_amount_usdc:.0f} USDC")
    
    # é£é™©å›æŠ¥æ¯”è®¾ç½®
    system_logger.info("ğŸ“ˆ é£é™©å›æŠ¥æ¯”è®¾ç½®:")
    system_logger.info(f"   æœ€å°R:Ræ¯”ä¾‹: {config.rr_min_threshold:.1f}:1")
    system_logger.info(f"   æ¿€è¿›R:Ræ¯”ä¾‹: {config.rr_aggressive_threshold:.1f}:1")
    system_logger.info(f"   æ¿€è¿›æ¨¡å¼é£é™©: {config.risk_aggressive*100:.1f}%")
    
    # æŠ€æœ¯åˆ†æå‚æ•°
    system_logger.info("ğŸ“Š æŠ€æœ¯åˆ†æå‚æ•°:")
    system_logger.info(f"   æˆäº¤é‡ç¡®è®¤é˜ˆå€¼: {config.volume_confirmation_threshold:.1f}x MA")
    system_logger.info(f"   FVGå †å è¦æ±‚: {config.fvg_stack_threshold}ä¸ª")
    system_logger.info(f"   æ–°é²œåŒºåŸŸæœ€å¤§äº¤äº’: {config.max_zone_interactions}æ¬¡")
    system_logger.info(f"   èœ¡çƒ›å›¾å½¢æƒé‡: {config.candle_pattern_weight:.1f}x")
    
    # AI å‚æ•°
    system_logger.info("ğŸ¤– AI åˆ†æå‚æ•°:")
    system_logger.info(f"   DeepSeek æ¸©åº¦: {config.temperature}")
    system_logger.info(f"   è¶…æ—¶æ—¶é—´: {config.deepseek_timeout}ç§’")
    
    # ç›‘æ§å‚æ•°
    system_logger.info("ğŸ“¡ ç›‘æ§å‚æ•°:")
    system_logger.info(f"   å¿ƒè·³é—´éš”: {config.heartbeat_interval}ç§’")
    system_logger.info(f"   ä»·æ ¼ç›‘æ§é—´éš”: {config.price_monitor_interval}ç§’")
    
    # é€»è¾‘æ¡ä»¶æ€»ç»“
    system_logger.info("ğŸ§  å…³é”®é€»è¾‘æ¡ä»¶:")
    system_logger.info("   1. ä»·æ ¼å¿…é¡»æ¥è¿‘å…³é”®æ°´å¹³ (æ¿€æ´»é˜ˆå€¼å†…)")
    if config.enable_kill_zone:
        system_logger.info(f"   2. å¿…é¡»åœ¨Kill Zoneæ—¶é—´å†… (UTC {config.kill_zone_start_utc}-{config.kill_zone_end_utc})")
    else:
        system_logger.info("   2. Kill Zoneå·²ç¦ç”¨ï¼Œå…¨å¤©å€™äº¤æ˜“")
    system_logger.info("   3. é£é™©å›æŠ¥æ¯”å¿…é¡»æ»¡è¶³æœ€å°è¦æ±‚")
    system_logger.info("   4. è´¦æˆ·ä½™é¢å¿…é¡»å……è¶³")
    system_logger.info("   5. æ— ç°æœ‰æŒä»“å†²çª")
    system_logger.info("   6. æŠ€æœ¯æŒ‡æ ‡ç¡®è®¤ä¿¡å·")
    
    system_logger.info("=" * 80)

def initialize_globals():
    """åˆå§‹åŒ–å…¨å±€é…ç½®å’Œå®¢æˆ·ç«¯ï¼Œé¿å…é‡å¤åˆå§‹åŒ–"""
    global config, deepseek_client, exchange
    
    if config is not None:
        return  # å·²ç»åˆå§‹åŒ–è¿‡äº†
    
    config = Config()
    
    # æ˜¾ç¤ºè¯¦ç»†çš„å¯åŠ¨å‚æ•°æŠ¥å‘Š
    _display_startup_parameters(config)
    
    # Use system logger to record config validation
    system_logger.info("Config validation successful: %s | Leverage=%dx | Risk=%.1f%% | Mode=%s", 
                       config.symbol, config.leverage, config.risk_per_trade*100, 
                       "Simulation" if config.simulation_mode else "Live")

    # Initialize DeepSeek client with error handling
    try:
        deepseek_client = OpenAI(
            api_key=os.getenv('DEEPSEEK_API_KEY'),
            base_url="https://api.deepseek.com/v1",
            timeout=config.deepseek_timeout
        )
        system_logger.info("DeepSeek client initialized successfully")
    except Exception as e:
        system_logger.error(f"Failed to initialize DeepSeek client: {e}")
        deepseek_client = None

    exchange = ccxt.hyperliquid({
        'enableRateLimit': True,
        'options': {'defaultType': 'perpetual'},
        'apiKey': os.getenv('HYPERLIQUID_WALLET_ADDRESS'),
        'secret': os.getenv('HYPERLIQUID_PRIVATE_KEY'),
        'walletAddress': os.getenv('HYPERLIQUID_WALLET_ADDRESS'),
    })

    # Fix for Hyperliquid privateKey initialization issue
    private_key = os.getenv('HYPERLIQUID_PRIVATE_KEY')
    if private_key and private_key.startswith('0x'):
        exchange.privateKey = private_key[2:]  # Remove 0x prefix
    else:
        exchange.privateKey = private_key

class PositionInfo(TypedDict):
    side: str
    size: float
    entry_price: float
    unrealized_pnl: float
    leverage: float
    symbol: str
    entry_time: Optional[datetime]
    liquidation_price: float  # New: Track liquidation price as SL

class PositionStore:
    def __init__(self):
        self._lock = threading.RLock()
        self._position: Optional[PositionInfo] = None

    def get(self) -> Optional[PositionInfo]:
        with self._lock:
            return self._position.copy() if self._position else None

    def set(self, pos: Optional[PositionInfo]):
        with self._lock:
            self._position = pos.copy() if pos else None

    def clear(self):
        with self._lock:
            self._position = None

def retry_on_exception(retries=5, backoff_factor=0.5, allowed_exceptions=(NetworkError, RequestTimeout, ExchangeError)):
    def deco(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            tries = 0
            while True:
                try:
                    return func(*args, **kwargs)
                except allowed_exceptions as e:
                    tries += 1
                    if tries > retries:
                        raise
                    sleep = backoff_factor * (2 ** (tries - 1)) + random.random() * 0.1
                    # Use system logger for retry info
                    system_logger = logging.getLogger('system')
                    system_logger.warning(f"Call to {func.__name__} failed (attempt {tries}/{retries}), waiting {sleep:.2f}s: {e}")
                    time.sleep(sleep)
        return wrapper
    return deco

# FIXED: Data Fetch 1 - æ·»åŠ å¸¦é‡è¯•çš„ sessionï¼Œç”¨äº CoinDesk è¯·æ±‚
def create_session_with_retry():
    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=5, pool_maxsize=5)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    # FIXED: SSL 5 - åº”ç”¨è‡ªå®šä¹‰ SSL ä¸Šä¸‹æ–‡ (æ³¨æ„ï¼šrequests.Session.verify åº”è¯¥æ˜¯å¸ƒå°”å€¼æˆ–è¯ä¹¦è·¯å¾„)
    session.verify = True  # å¯ç”¨SSLéªŒè¯
    return session

class TradingBot:
    def __init__(self, config: Config, exchange=None):
        self.config = config
        self.exchange = exchange
        # Initialize category loggers
        self.logger_trading = logging.getLogger('trading')
        self.logger_api = logging.getLogger('api')
        self.logger_risk = logging.getLogger('risk')
        self.logger_monitor = logging.getLogger('monitor')
        self.logger_system = logging.getLogger('system')

        self.signal_history: List[Dict[str, Any]] = []
        self.key_levels_cache: Optional[Dict[str, float]] = None
        self.cache_timestamp: float = 0
        self.initial_balance: float = 0
        self.last_activation_time: float = 0
        self.level_activation_times: Dict[str, float] = {}  # Track last activation time per key level
        # New: Track zone interactions for freshness
        self.zone_interactions: Dict[str, int] = {}  # Count interactions per zone
        self.last_scheduled_signal: Optional[Dict[str, Any]] = None  # Store last scheduled signal copy
        self.lock = threading.RLock()
        self.trade_lock = threading.RLock()
        self.position_store = PositionStore()
        self.executor = ThreadPoolExecutor(max_workers=3)
        # FIXED: Medium 4 - Cache for indicators
        self.indicators_cache: Dict[str, pd.DataFrame] = {}
        # New: Risk control tracking
        self.daily_start_balance: float = 0
        self.peak_balance: float = 0
        self.current_balance: float = 0
        self.last_reset_date: str = ""
        self.last_reset_4h: datetime = datetime.now(timezone.utc)  # New: For 4h reset
        # API health status tracking
        self.api_health_status = {
            'deepseek': {'status': 'unknown', 'last_check': 0, 'consecutive_failures': 0},
            'hyperliquid': {'status': 'unknown', 'last_check': 0, 'consecutive_failures': 0},
            'websocket': {'status': 'unknown', 'last_check': 0, 'consecutive_failures': 0}
        }
        
        # FIXED: Data Fetch 3 - åˆ›å»ºå¸¦é‡è¯•çš„ session
        self.session = create_session_with_retry()
        
        # Initialize CoinDesk WebSocket API (primary) and Hyperliquid backup providers
        self.coindesk_provider = None
        self.hyperliquid_websocket_backup = None
        self.hyperliquid_backup = None
        
        # Initialize data providers (currently disabled due to missing modules)
        self.coindesk_provider = None
        self.hyperliquid_websocket_backup = None
        self.hyperliquid_backup = None
        self.hyperliquid_market_data = None
        
        # Note: Custom data providers are disabled as modules are not available
        self.logger_system.warning("Custom data providers (CoinDesk, Hyperliquid WebSocket) are disabled - modules not available")
        self.logger_system.info("Using fallback to exchange API for data fetching")
        
        # Data source priority explanation
        self.logger_system.info("Data source: Exchange API (Hyperliquid) - primary and only available source")
        
        self.api_health_check_interval = 300  # Check every 5 minutes
        # Threshold accumulation and win rate stats
        self.level_activation_stats: Dict[str, Dict[str, int]] = {}  # Activation and success stats per key level
        self.total_activations: int = 0  # Total activations
        self.total_successful_trades: int = 0  # Total successful trades
        self.total_failed_trades: int = 0  # Total failed trades
        
        # Log counters (for sampling)
        self.log_counters = {
            'price_activation': 0,
            'api_health_check': 0,
            'heartbeat': 0
        }
        
        # Perform initial API health check
        self._perform_initial_api_health_check()
        # New: Dynamic SL/TP monitor thread
        self.sl_tp_monitor_thread = None

    @retry_on_exception(retries=4)
    def safe_create_order(self, exchange, symbol, side, amount, params=None):
        if self.config.simulation_mode:
            # Simulation mode returns simulated order
            order_id = f"sim_{int(time.time() * 1000)}"
            ticker = self.safe_fetch_ticker(exchange, symbol)
            price = ticker['last'] if ticker else 67000.0  # Use default price as backup
            cost = amount * price
            
            order = {
                'id': order_id,
                'symbol': symbol,
                'status': 'closed',
                'filled': amount,
                'remaining': 0.0,
                'side': side,
                'type': 'market',
                'amount': amount,
                'price': price,
                'average': price,
                'cost': cost,
                'fee': {'cost': cost * self.config.fee_rate, 'currency': 'USDT'},
                'timestamp': int(time.time() * 1000),
                'datetime': datetime.now(timezone.utc).isoformat(),
                'simulated': True
            }
            self.logger_trading.info(f"Simulated order placed successfully, ID: {order_id}")
            return order
            
        try:
            # FIXED: High 1 & 6 - Use create_order for full params support; confirm after slippage
            order = exchange.create_order(symbol, side, 'market', amount, None, params=params)
            self.logger_trading.info(f"Order placed successfully, ID: {order.get('id', 'N/A')}")  # FIXED: Medium 3 - Use debug for ID?
            self.logger_trading.debug(f"Order ID: {order.get('id', 'N/A')}")  # Safer
            # FIXED: High 6 - Confirm after any order
            if hasattr(self, 'confirm_order'):  # Ensure method exists
                if not self.confirm_order(order['id'], amount):
                    raise ExchangeError("Order confirmation failed")
            return order
        except ExchangeError as e:
            if "slippage" in str(e).lower():
                self.logger_trading.warning(f"Slippage error in order: {e}")
            raise

    # FIXED: Data Fetch 4 - å¢å¼º safe_fetch_ohlcvï¼Œæ·»åŠ  session å’Œ TF å¡«å……
    @retry_on_exception(retries=4)
    def safe_fetch_ohlcv(self, exchange, symbol, timeframe, limit=100, session=None):
        """Enhanced OHLCV fetch with fallback data filling"""
        try:
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
            if ohlcv and len(ohlcv) >= min(20, limit):  # FIXED: Data 1 - éªŒè¯æ•°æ®å®Œæ•´æ€§
                return ohlcv
            else:
                self.logger_api.warning(f"Insufficient data for {timeframe} ({len(ohlcv) if ohlcv else 0} rows), no fallback available")
                return []  # è¿”å›ç©ºæ•°æ®
        except Exception as e:
            self.logger_api.error(f"Fetch OHLCV failed for {timeframe}: {e}")
            return []

    def safe_fetch_ticker(self, exchange, symbol):
        try:
            return exchange.fetch_ticker(symbol)
        except Exception as e:
            self.logger_api.warning(f"Ticker fetch failed for {symbol}: {e}")
            return {'last': 67000.0}  # Fallback price

    def _perform_initial_api_health_check(self):
        self.logger_api.info("Performing initial API health check...")
        # DeepSeek check
        try:
            if deepseek_client is None:
                raise Exception("DeepSeek client not initialized")
            
            test_prompt = "test"
            
            # è®°å½•å¥åº·æ£€æŸ¥çš„æç¤ºè¯
            self.logger_api.info("ğŸ” APIå¥åº·æ£€æŸ¥ - å‘é€æµ‹è¯•æç¤ºè¯:")
            self.logger_api.info(f"   æç¤ºè¯: '{test_prompt}'")
            self.logger_api.info(f"   æ¨¡å‹: deepseek-chat")
            self.logger_api.info(f"   æœ€å¤§tokens: 10")
            self.logger_api.info(f"   æ¸©åº¦: {config.temperature}")
                
            response = deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": test_prompt}],
                max_tokens=10,
                temperature=config.temperature
            )
            
            # è®°å½•å¥åº·æ£€æŸ¥çš„å“åº”
            response_text = response.choices[0].message.content.strip()
            self.logger_api.info("âœ… APIå¥åº·æ£€æŸ¥ - æ”¶åˆ°å“åº”:")
            self.logger_api.info(f"   å“åº”å†…å®¹: '{response_text}'")
            
            self.api_health_status['deepseek']['status'] = 'healthy'
            self.api_health_status['deepseek']['last_check'] = time.time()
            self.api_health_status['deepseek']['consecutive_failures'] = 0
            self.logger_api.info("DeepSeek API healthy")
        except Exception as e:
            self.api_health_status['deepseek']['status'] = 'unhealthy'
            self.api_health_status['deepseek']['consecutive_failures'] += 1
            self.logger_api.error(f"DeepSeek API health check failed: {e}")

    def setup_exchange(self):
        try:
            self.logger_trading.info("Setting up exchange...")
            # Set leverage
            leverage_result = exchange.set_leverage(config.leverage, config.symbol)
            self.logger_trading.info(f"Leverage set result: {leverage_result}")
            # Verify leverage
            positions = exchange.fetch_positions([config.symbol])
            if positions:
                actual_leverage = positions[0].get('leverage', config.leverage)
                self.logger_trading.info(f"Leverage verification successful: Expected {config.leverage}x, actual {actual_leverage}x")
            else:
                self.logger_trading.debug("No active position found - leverage verification skipped")
            self.logger_trading.info(f"Set leverage: {config.leverage}x")
            # Fetch balance
            balance = exchange.fetch_balance()
            usdc_balance = balance.get('USDC', {}).get('free', 0)
            self.logger_system.info(f"Current USD balance: {usdc_balance:.2f}")
            self.initial_balance = usdc_balance
            return True
        except Exception as e:
            self.logger_trading.error(f"Exchange setup failed: {e}")
            return False

    def load_signal_history(self):
        try:
            if os.path.exists(config.signals_file):
                with open(config.signals_file, 'r') as f:
                    self.signal_history = json.load(f)
                self.logger_system.info(f"Loaded signal history: {len(self.signal_history)} records")
            else:
                self.signal_history = []
        except Exception as e:
            self.logger_system.error(f"Failed to load signal history: {e}")
            self.signal_history = []

    def save_signal_history(self):
        try:
            with open(config.signals_file, 'w') as f:
                json.dump(self.signal_history, f, indent=2)
            self.logger_system.debug("Signal history saved successfully")
        except Exception as e:
            self.logger_system.error(f"Failed to save signal history: {e}")

    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        if df.empty:
            return df
        # Basic indicators (expand as needed)
        df['sma_20'] = df['close'].rolling(20).mean()
        df['ema_20'] = df['close'].ewm(span=20).mean()
        df['rsi'] = self._rsi(df['close'], 14)
        df['atr'] = self._atr(df, 14)
        return df

    def _rsi(self, series: pd.Series, period: int = 14) -> pd.Series:
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def _atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        tr = np.maximum(high_low, np.maximum(high_close, low_close))
        return tr.rolling(period).mean()

    def calculate_key_levels(self, multi_tf_data: Dict[str, pd.DataFrame]) -> Dict[str, float]:
        key_levels = {}
        # Simplified key level calculation (expand based on liquidity_priority)
        for tf, df in multi_tf_data.items():
            if not df.empty:
                key_levels[f'{tf}_high'] = df['high'].max()
                key_levels[f'{tf}_low'] = df['low'].min()
                key_levels[f'{tf}_open'] = df['open'].iloc[-1]
        return key_levels

    def check_price_activation(self, current_price: float, key_levels: Dict[str, float]) -> Tuple[bool, Optional[str]]:
        """æ™ºèƒ½ä»·æ ¼æ¿€æ´»æ£€æŸ¥ï¼Œæ”¯æŒå¤šå±‚æ¬¡æ¿€æ´»é˜ˆå€¼"""
        if not key_levels:
            return False, None
            
        closest_level = None
        closest_distance = float('inf')
        closest_level_name = None
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„å…³é”®æ°´å¹³
        for level_name, level_price in key_levels.items():
            if level_price > 0:  # ç¡®ä¿ä»·æ ¼æœ‰æ•ˆ
                distance = abs(current_price - level_price) / level_price
                if distance < closest_distance:
                    closest_distance = distance
                    closest_level = level_price
                    closest_level_name = level_name
        
        # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼ï¼šåŸºç¡€é˜ˆå€¼ + æ³¢åŠ¨æ€§è°ƒæ•´
        base_threshold = self.config.activation_threshold
        
        # å¦‚æœè·ç¦»åœ¨åŸºç¡€é˜ˆå€¼å†…ï¼Œç›´æ¥æ¿€æ´»
        if closest_distance <= base_threshold:
            self.logger_system.debug(f"ä»·æ ¼æ¿€æ´»: {closest_level_name} (è·ç¦»: {closest_distance*100:.3f}%)")
            return True, closest_level_name
        
        # å¦‚æœè·ç¦»åœ¨æ‰©å±•é˜ˆå€¼å†…ï¼ˆ2å€åŸºç¡€é˜ˆå€¼ï¼‰ï¼Œä¸”æ»¡è¶³å…¶ä»–æ¡ä»¶ï¼Œä¹Ÿå¯ä»¥æ¿€æ´»
        extended_threshold = base_threshold * 2
        if closest_distance <= extended_threshold:
            # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…
            now_utc = datetime.now(timezone.utc).hour
            if self.config.enable_kill_zone and (self.config.kill_zone_start_utc <= now_utc <= self.config.kill_zone_end_utc):
                self.logger_system.debug(f"æ‰©å±•æ¿€æ´»: {closest_level_name} (è·ç¦»: {closest_distance*100:.3f}%, åœ¨äº¤æ˜“æ—¶é—´å†…)")
                return True, closest_level_name
        
        # è®°å½•æœ€æ¥è¿‘çš„æ°´å¹³ï¼ˆé™ä½æ—¥å¿—é¢‘ç‡ï¼‰
        if hasattr(self, '_last_closest_log_time'):
            if time.time() - self._last_closest_log_time > 300:  # æ¯5åˆ†é’Ÿè®°å½•ä¸€æ¬¡
                self.logger_system.debug(f"æœ€æ¥è¿‘å…³é”®æ°´å¹³: {closest_level_name} @ ${closest_level:.2f} (è·ç¦»: {closest_distance*100:.3f}%)")
                self._last_closest_log_time = time.time()
        else:
            self._last_closest_log_time = time.time()
        
        return False, None

    def _fetch_and_update_data(self, activated_level: Optional[str] = None):
        # Fetch multi-TF data using enhanced safe_fetch_ohlcv
        multi_tf_data = {}
        failed_timeframes = []
        successful_timeframes = []
        
        self.logger_system.info(f"å¼€å§‹è·å–å¤šæ—¶é—´æ¡†æ¶æ•°æ®: {config.timeframes}")
        
        for tf in config.timeframes:
            try:
                ohlcv = self.safe_fetch_ohlcv(self.exchange, config.symbol, tf, config.data_points)
                if ohlcv and len(ohlcv) > 0:
                    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
                    df = df.set_index('timestamp')
                    df = self.calculate_technical_indicators(df)
                    multi_tf_data[tf] = df
                    successful_timeframes.append(tf)
                    self.logger_system.debug(f"âœ… {tf} æ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡è®°å½•")
                else:
                    failed_timeframes.append(tf)
                    self.logger_system.warning(f"âŒ {tf} æ•°æ®è·å–å¤±è´¥: æ— æ•°æ®è¿”å›")
            except Exception as e:
                failed_timeframes.append(tf)
                self.logger_system.error(f"âŒ {tf} æ•°æ®è·å–å¼‚å¸¸: {e}")

        # æ•°æ®è·å–ç»“æœç»Ÿè®¡
        success_rate = len(successful_timeframes) / len(config.timeframes) * 100
        self.logger_system.info(f"æ•°æ®è·å–å®Œæˆ: æˆåŠŸ {len(successful_timeframes)}/{len(config.timeframes)} ({success_rate:.1f}%)")
        
        if successful_timeframes:
            self.logger_system.info(f"æˆåŠŸè·å–: {', '.join(successful_timeframes)}")
        if failed_timeframes:
            self.logger_system.warning(f"è·å–å¤±è´¥: {', '.join(failed_timeframes)}")

        if not multi_tf_data:
            self.logger_system.error("æ‰€æœ‰æ—¶é—´æ¡†æ¶æ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åˆ†æ")
            return None

        # è·å–å½“å‰ä»·æ ¼ï¼ˆå®¹é”™å¤„ç†ï¼‰
        try:
            ticker = self.safe_fetch_ticker(self.exchange, config.symbol)
            current_price = ticker['last'] if ticker and 'last' in ticker else None
            if current_price is None:
                # å¦‚æœæ— æ³•è·å–tickerï¼Œå°è¯•ä»æœ€æ–°çš„OHLCVæ•°æ®è·å–
                if multi_tf_data and config.primary_timeframe in multi_tf_data:
                    current_price = multi_tf_data[config.primary_timeframe]['close'].iloc[-1]
                    self.logger_system.warning(f"ä»{config.primary_timeframe}æ•°æ®è·å–å½“å‰ä»·æ ¼: ${current_price:.2f}")
                else:
                    current_price = 4000.0  # ETHçš„åˆç†é»˜è®¤ä»·æ ¼
                    self.logger_system.error(f"æ— æ³•è·å–å½“å‰ä»·æ ¼ï¼Œä½¿ç”¨é»˜è®¤å€¼: ${current_price:.2f}")
            else:
                self.logger_system.debug(f"æˆåŠŸè·å–å½“å‰ä»·æ ¼: ${current_price:.2f}")
        except Exception as e:
            current_price = 4000.0  # ETHçš„åˆç†é»˜è®¤ä»·æ ¼
            self.logger_system.error(f"ä»·æ ¼è·å–å¼‚å¸¸: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼: ${current_price:.2f}")

        # Calculate amplitude (å®¹é”™å¤„ç†)
        try:
            if multi_tf_data:
                amplitudes = []
                for tf, df in multi_tf_data.items():
                    if not df.empty and len(df) > 0:
                        amp = df['high'].max() - df['low'].min()
                        amplitudes.append(amp)
                avg_amplitude = np.mean(amplitudes) if amplitudes else current_price * 0.05
            else:
                avg_amplitude = current_price * 0.05  # é»˜è®¤5%æŒ¯å¹…
            amplitude = {'avg_amplitude': avg_amplitude}
            self.logger_system.debug(f"è®¡ç®—æŒ¯å¹…: {avg_amplitude:.2f}")
        except Exception as e:
            amplitude = {'avg_amplitude': current_price * 0.05}
            self.logger_system.warning(f"æŒ¯å¹…è®¡ç®—å¼‚å¸¸: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")

        # Update cache (å®¹é”™å¤„ç†)
        try:
            with self.lock:
                self.key_levels_cache = self.calculate_key_levels(multi_tf_data)
                self.cache_timestamp = time.time()
            self.logger_system.debug(f"å…³é”®æ°´å¹³ç¼“å­˜æ›´æ–°æˆåŠŸ: {len(self.key_levels_cache)} ä¸ªæ°´å¹³")
        except Exception as e:
            self.logger_system.error(f"å…³é”®æ°´å¹³è®¡ç®—å¼‚å¸¸: {e}")
            # ä¿æŒç°æœ‰ç¼“å­˜æˆ–ä½¿ç”¨ç©ºç¼“å­˜
            if not hasattr(self, 'key_levels_cache') or not self.key_levels_cache:
                self.key_levels_cache = {}

        # Volatility (å®¹é”™å¤„ç†)
        try:
            if multi_tf_data:
                volatilities = []
                for tf, df in multi_tf_data.items():
                    if not df.empty and len(df) > 1:
                        vol = df['close'].pct_change().std() * 100
                        if not np.isnan(vol):
                            volatilities.append(vol)
                volatility = np.std(volatilities) if volatilities else 2.0
            else:
                volatility = 2.0  # é»˜è®¤æ³¢åŠ¨ç‡
            self.logger_system.debug(f"è®¡ç®—æ³¢åŠ¨ç‡: {volatility:.2f}%")
        except Exception as e:
            volatility = 2.0
            self.logger_system.warning(f"æ³¢åŠ¨ç‡è®¡ç®—å¼‚å¸¸: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")

        # æ„å»ºåŸºç¡€ä»·æ ¼æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æ¿€æ´»éƒ½éœ€è¦ï¼‰
        price_data = {
            'price': current_price,
            'multi_tf_data': multi_tf_data,
            'amplitude': amplitude,
            'volatility': volatility,
            'key_levels': self.key_levels_cache,
            'technical_data': {
                'rsi': multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).iloc[-1].get('rsi', 50) if not multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).empty else 50,
                'macd': multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).iloc[-1].get('macd', 0) if not multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).empty else 0,
                'sma_20': multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).iloc[-1].get('sma_20', current_price) if not multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).empty else current_price,
                'atr': multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).iloc[-1].get('atr', current_price * 0.02) if not multi_tf_data.get(config.primary_timeframe, pd.DataFrame()).empty else current_price * 0.02
            },
            'activated_level': None,  # åˆå§‹åŒ–æ¿€æ´»æ°´å¹³
            'is_activated': False     # åˆå§‹åŒ–æ¿€æ´»çŠ¶æ€
        }

        # ä»·æ ¼æ¿€æ´»æ£€æŸ¥ï¼ˆä¸å½±å“æ•°æ®è¿”å›ï¼‰
        if not activated_level:
            with self.lock:
                if self.key_levels_cache:
                    is_activated, activated = self.check_price_activation(current_price, self.key_levels_cache)
                    price_data['is_activated'] = is_activated
                    if is_activated:
                        price_data['activated_level'] = activated
                        self.logger_system.info(f"ä»·æ ¼æ¿€æ´»æˆåŠŸ: {activated} (è·ç¦»: {abs(current_price - self.key_levels_cache.get(activated, current_price)) / current_price * 100:.3f}%)")
                    else:
                        # é™ä½æ—¥å¿—çº§åˆ«ï¼Œé¿å…é¢‘ç¹çš„INFOæ—¥å¿—
                        self.logger_system.debug("Price not close to key level, will use fallback signal if needed")
        else:
            # å¦‚æœæä¾›äº†activated_levelï¼ˆå¦‚æµ‹è¯•æ¨¡å¼ï¼‰ï¼Œè·³è¿‡ä»·æ ¼æ¿€æ´»æ£€æŸ¥
            price_data['activated_level'] = activated_level
            price_data['is_activated'] = True
            self.logger_system.debug(f"Using provided activated level: {activated_level}")

        # Real-time bar update (simplified)
        primary_tf = self.config.primary_timeframe
        try:
            latest_ohlcv = self.safe_fetch_ohlcv(self.exchange, self.config.symbol, primary_tf, 1)
            if latest_ohlcv:
                new_row = pd.DataFrame(latest_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                new_row['timestamp'] = pd.to_datetime(new_row['timestamp'], unit='ms', utc=True)
                new_row = new_row.set_index('timestamp')
                df_primary = price_data['multi_tf_data'][primary_tf]
                if not df_primary.empty and df_primary.index[-1] < new_row.index[0]:
                    updated_df = pd.concat([df_primary, new_row])
                    if len(updated_df) > self.config.data_points:
                        updated_df = updated_df.tail(self.config.data_points)
                    updated_df = self.calculate_technical_indicators(updated_df)
                    price_data['multi_tf_data'][primary_tf] = updated_df
                    current_data = updated_df.iloc[-1]
                    price_data.update({
                        'price': current_price,
                        'high': max(current_data['high'], current_price),
                        'low': min(current_data['low'], current_price),
                        'technical_data': {
                            **price_data['technical_data'],
                            'rsi': current_data.get('rsi', price_data['technical_data'].get('rsi', 50)),
                            'macd': current_data.get('macd', price_data['technical_data'].get('macd', 0)),
                            'sma_20': current_data.get('sma_20', price_data['technical_data'].get('sma_20', current_price)),
                            'atr': current_data.get('atr', price_data['technical_data'].get('atr', current_price * 0.02))
                        }
                    })
                    self.logger_system.info("Real-time K-line update successful")
        except Exception as update_e:
            self.logger_system.exception(f"Real-time K-line update failed: {update_e}")

        price_data['key_levels']['current_price'] = current_price
        # Extract base currency name from trading pair
        base_currency = self.config.symbol.split('/')[0]
        self.logger_system.info(f"{base_currency} current price: ${price_data['price']:,.2f}")
        self.logger_system.info(f"Primary timeframe: {self.config.primary_timeframe}")
        self.logger_system.info(f"Weekly average amplitude: {price_data['amplitude']['avg_amplitude']:.2f}")
        self.logger_system.info(f"Completed volatility: {price_data.get('volatility', 0):.1f}%")
        return price_data

    def intraday_momentum_filter(self, price_data: Dict[str, Any]) -> bool:
        # Simplified momentum filter (expand as needed)
        rsi = price_data['technical_data'].get('rsi', 50)
        return 30 < rsi < 70  # Neutral RSI for momentum

    def analyze_with_deepseek(self, price_data: Dict[str, Any], activated_level: Optional[str]) -> Optional[Dict[str, Any]]:
        try:
            if deepseek_client is None:
                self.logger_system.error("DeepSeek client not available")
                return None
                
            prompt = f"""
            Analyze the following market data for {config.symbol}:
            Current price: {price_data['price']}
            Activated level: {activated_level}
            RSI: {price_data['technical_data']['rsi']:.2f}
            Volatility: {price_data['volatility']:.1f}%
            
            Provide a trading signal analysis. Return ONLY a valid JSON object with these exact fields:
            {{
                "signal": "BUY" or "SELL" or "HOLD",
                "entry_price": {price_data['price']},
                "stop_loss": number,
                "take_profit": number,
                "confidence": "LOW" or "MEDIUM" or "HIGH",
                "reason": "brief explanation"
            }}
            
            Make sure stop_loss and take_profit are realistic prices based on current price.
            """
            
            # è®°å½•å‘é€ç»™DeepSeekçš„å®Œæ•´æç¤ºè¯
            self.logger_system.info("=" * 80)
            self.logger_system.info("ğŸ“¤ å‘é€ç»™DeepSeekçš„æç¤ºè¯:")
            self.logger_system.info("-" * 40)
            self.logger_system.info(prompt.strip())
            self.logger_system.info("-" * 40)
            
            response = deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=config.temperature
            )
            
            signal_text = response.choices[0].message.content.strip()
            
            # è®°å½•DeepSeekçš„å®Œæ•´å“åº”
            self.logger_system.info("ğŸ“¥ DeepSeekçš„å®Œæ•´å“åº”:")
            self.logger_system.info("-" * 40)
            self.logger_system.info(signal_text)
            self.logger_system.info("-" * 40)
            self.logger_system.info("=" * 80)
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            try:
                # æŸ¥æ‰¾JSONå¼€å§‹å’Œç»“æŸä½ç½®
                start_idx = signal_text.find('{')
                end_idx = signal_text.rfind('}') + 1
                
                if start_idx != -1 and end_idx > start_idx:
                    json_str = signal_text[start_idx:end_idx]
                    signal_data = json.loads(json_str)
                else:
                    raise ValueError("No valid JSON found in response")
                    
            except (json.JSONDecodeError, ValueError) as e:
                self.logger_system.warning(f"JSON parsing failed: {e}, using fallback signal")
                # ç”Ÿæˆfallbackä¿¡å·
                signal_data = self._generate_fallback_signal(price_data, activated_level)
            
            # éªŒè¯ä¿¡å·æ•°æ®å®Œæ•´æ€§
            required_fields = ['signal', 'entry_price', 'stop_loss', 'take_profit', 'confidence', 'reason']
            if not all(field in signal_data for field in required_fields):
                self.logger_system.warning("Incomplete signal data, using fallback")
                signal_data = self._generate_fallback_signal(price_data, activated_level)
            
            # éªŒè¯ä¿¡å·å€¼çš„åˆç†æ€§
            if signal_data['signal'] not in ['BUY', 'SELL', 'HOLD']:
                signal_data['signal'] = 'HOLD'
            
            self.logger_system.info(f"Generated signal: {signal_data['signal']} at {signal_data['entry_price']:.2f}")
            return signal_data
            
        except Exception as e:
            self.logger_system.error(f"DeepSeek analysis failed: {e}")
            # è¿”å›fallbackä¿¡å·è€Œä¸æ˜¯None
            return self._generate_fallback_signal(price_data, activated_level)

    def _generate_fallback_signal(self, price_data: Dict[str, Any], activated_level: Optional[str]) -> Dict[str, Any]:
        """ç”Ÿæˆå¤‡ç”¨äº¤æ˜“ä¿¡å·ï¼ŒåŸºäºæŠ€æœ¯æŒ‡æ ‡"""
        try:
            current_price = price_data['price']
            rsi = price_data['technical_data'].get('rsi', 50)
            
            # åŸºäºRSIçš„ç®€å•ç­–ç•¥
            if rsi < 30:
                signal = 'BUY'
                reason = f'RSI oversold ({rsi:.1f})'
                stop_loss = current_price * 0.98  # 2% æ­¢æŸ
                take_profit = current_price * 1.04  # 4% æ­¢ç›ˆ
            elif rsi > 70:
                signal = 'SELL'
                reason = f'RSI overbought ({rsi:.1f})'
                stop_loss = current_price * 1.02  # 2% æ­¢æŸ
                take_profit = current_price * 0.96  # 4% æ­¢ç›ˆ
            else:
                signal = 'HOLD'
                reason = f'RSI neutral ({rsi:.1f})'
                stop_loss = current_price * 0.99
                take_profit = current_price * 1.01
            
            return {
                'signal': signal,
                'entry_price': current_price,
                'stop_loss': stop_loss,
                'take_profit': take_profit,
                'confidence': 'MEDIUM',
                'reason': reason
            }
            
        except Exception as e:
            self.logger_system.error(f"Fallback signal generation failed: {e}")
            # æœ€åçš„ä¿é™©ä¿¡å·
            return {
                'signal': 'HOLD',
                'entry_price': price_data.get('price', 4000),
                'stop_loss': price_data.get('price', 4000) * 0.99,
                'take_profit': price_data.get('price', 4000) * 1.01,
                'confidence': 'LOW',
                'reason': 'Fallback signal due to error'
            }

    def execute_trade(self, signal_data: Dict[str, Any], price_data: Dict[str, Any], activated_level: Optional[str]):
        """æ‰§è¡Œäº¤æ˜“ï¼ŒåŒ…å«å®Œæ•´çš„é£é™©æ£€æŸ¥å’Œé”™è¯¯å¤„ç†"""
        try:
            signal = signal_data.get('signal', 'HOLD')
            
            # å¦‚æœä¿¡å·æ˜¯HOLDï¼Œä¸æ‰§è¡Œäº¤æ˜“
            if signal == 'HOLD':
                self.logger_trading.info("Signal is HOLD, no trade executed")
                return
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒä»“
            current_position = self.position_store.get()
            if current_position:
                self.logger_trading.warning("Already have open position, skipping new trade")
                return
            
            # è·å–å½“å‰ä½™é¢
            try:
                balance = self.exchange.fetch_balance()
                usdc_balance = balance.get('USDC', {}).get('free', 0)
                
                if usdc_balance < self.config.min_amount_usdc:
                    self.logger_trading.error(f"Insufficient balance: {usdc_balance:.2f} USDC < {self.config.min_amount_usdc}")
                    return
                    
            except Exception as e:
                self.logger_trading.error(f"Failed to fetch balance: {e}")
                return
            
            # è®¡ç®—äº¤æ˜“å‚æ•°
            side = signal.lower()
            if side not in ['buy', 'sell']:
                self.logger_trading.error(f"Invalid signal: {signal}")
                return
            
            # è®¡ç®—äº¤æ˜“æ•°é‡ï¼ˆåŸºäºUSDCä½™é¢å’Œæ æ†ï¼‰
            current_price = price_data['price']
            max_position_value = usdc_balance * self.config.max_margin_usage
            amount = min(self.config.amount, max_position_value / current_price / self.config.leverage)
            
            if amount < 0.001:  # æœ€å°äº¤æ˜“é‡æ£€æŸ¥
                self.logger_trading.error(f"Trade amount too small: {amount}")
                return
            
            self.logger_trading.info(f"Executing {side.upper()} order: {amount:.4f} ETH at ~${current_price:.2f}")
            
            # æ‰§è¡Œè®¢å•
            params = {'reduce_only': False}
            order = self.safe_create_order(self.exchange, self.config.symbol, side, amount, params)
            
            if order:
                # è®°å½•æŒä»“ä¿¡æ¯
                position = {
                    'side': side,
                    'size': amount,
                    'entry_price': order.get('average', current_price),
                    'unrealized_pnl': 0,
                    'leverage': self.config.leverage,
                    'symbol': self.config.symbol,
                    'entry_time': datetime.now(timezone.utc),
                    'liquidation_price': signal_data.get('stop_loss', current_price * 0.95)
                }
                self.position_store.set(position)
                
                # è®°å½•äº¤æ˜“å†å²
                trade_record = {
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'signal': signal_data,
                    'order': order,
                    'activated_level': activated_level,
                    'price_data': {
                        'price': current_price,
                        'rsi': price_data['technical_data'].get('rsi', 50)
                    }
                }
                self.signal_history.append(trade_record)
                self.save_signal_history()
                
                self.logger_trading.info(f"âœ… Trade executed successfully: {side.upper()} {amount:.4f} ETH at ${order.get('average', current_price):.2f}")
                self.logger_trading.info(f"Stop Loss: ${signal_data.get('stop_loss', 0):.2f}, Take Profit: ${signal_data.get('take_profit', 0):.2f}")
                
            else:
                self.logger_trading.error("Order execution failed")
                
        except Exception as e:
            self.logger_trading.error(f"Trade execution error: {e}")
            import traceback
            self.logger_trading.debug(f"Trade execution traceback: {traceback.format_exc()}")

    def price_monitor_loop(self):
        """Price monitoring loop: Check real-time price close to key levels"""
        activation_count = 0
        monitor_cycle_count = 0
        
        while True:
            try:
                monitor_cycle_count += 1
                ticker = self.safe_fetch_ticker(self.exchange, config.symbol)
                current_price = ticker['last'] if ticker else 67000.0
                
                # FIXED: High 6 - Separate cache update and price check locks to avoid blocking
                cache_needs_update = False
                current_time = time.time()
                
                # Check if cache needs update (quick lock)
                with self.lock:
                    if current_time - self.cache_timestamp > self.config.cache_ttl:
                        cache_needs_update = True
                
                # Update cache outside of main lock to avoid blocking price checks
                if cache_needs_update:
                    try:
                        futures = {
                            self.executor.submit(self.safe_fetch_ohlcv, self.exchange, config.symbol, '4h', 201): '4h',
                            self.executor.submit(self.safe_fetch_ohlcv, self.exchange, config.symbol, '1d', 10): '1d',
                            self.executor.submit(self.safe_fetch_ohlcv, self.exchange, config.symbol, '1w', 5): '1w',
                            self.executor.submit(self.safe_fetch_ohlcv, self.exchange, config.symbol, '15m', 100): '15m'
                        }
                        multi_tf_light = {}
                        for future in as_completed(futures):
                            tf = futures[future]
                            try:
                                ohlcv = future.result()
                                if not ohlcv:  # Check None return value
                                    continue
                                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
                                df = self.calculate_technical_indicators(df)
                                multi_tf_light[tf] = df
                            except Exception as fetch_e:
                                self.logger_api.exception(f"Failed to fetch {tf} in monitor: {fetch_e}")
                        
                        # FIXED: High 6 - Only update cache if we have valid data
                        if multi_tf_light:
                            new_key_levels = self.calculate_key_levels(multi_tf_light)
                            # Update cache atomically
                            with self.lock:
                                self.key_levels_cache = new_key_levels
                                self.cache_timestamp = current_time
                            self.logger_monitor.debug("Key levels cache lightweight update successful")
                        else:
                            self.logger_monitor.warning("Cache update failed: no valid timeframe data")
                    except Exception as update_e:
                        self.logger_monitor.exception(f"Cache update failed, using old values: {update_e}")
                
                # Check price activation with current cache (separate lock)
                current_cache = None
                with self.lock:
                    current_cache = self.key_levels_cache.copy() if self.key_levels_cache else None
                
                if current_cache:
                    is_activated, activated = self.check_price_activation(current_price, current_cache)
                    if is_activated:
                        activation_count += 1
                        # Sample log: Log every 5 activations, or first activation
                        if activation_count == 1 or activation_count % 5 == 0:
                            self.logger_monitor.info("Price activation: %s (cumulative: %d times)", activated, activation_count)
                        else:
                            self.logger_monitor.debug("Price activation: %s (cumulative: %d times)", activated, activation_count)
                        threading.Thread(target=lambda: self.trading_bot(activated), daemon=True).start()
                    else:
                        # Sample log: Log normal status every 20 monitoring cycles
                        if monitor_cycle_count % 20 == 0:
                            self.logger_monitor.debug("Price monitoring normal: Price=%.2f, Cycle=%d", current_price, monitor_cycle_count)
                else:
                    self.logger_monitor.warning("No key levels cache available for price activation check")
                
                time.sleep(180)  # 3 minute price activation check interval
            except Exception as e:
                self.logger_system.exception(f"Price monitoring exception: {e}")
                time.sleep(self.config.price_monitor_interval)

    def heartbeat(self):
        """ç³»ç»Ÿå¿ƒè·³æ£€æŸ¥ï¼Œç›‘æ§å…³é”®æŒ‡æ ‡"""
        try:
            # ç¼“å­˜æœºåˆ¶ï¼šæ¯3æ¬¡å¿ƒè·³æ‰è·å–ä¸€æ¬¡ä½™é¢ï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰
            if not hasattr(self, '_heartbeat_count'):
                self._heartbeat_count = 0
                self._cached_balance = 0
                self._cached_price = 0
            
            self._heartbeat_count += 1
            
            # è·å–æŒä»“ä¿¡æ¯ï¼ˆæœ¬åœ°æ“ä½œï¼Œå¿«é€Ÿï¼‰
            position = self.position_store.get()
            position_info = position['side'] if position else 'No position'
            
            # æ¯3æ¬¡å¿ƒè·³è·å–ä¸€æ¬¡ä»·æ ¼å’Œä½™é¢
            if self._heartbeat_count % 3 == 1:
                # è·å–å½“å‰ä»·æ ¼
                ticker = self.safe_fetch_ticker(self.exchange, self.config.symbol)
                self._cached_price = ticker.get('last', self._cached_price) if ticker else self._cached_price
                
                # è·å–ä½™é¢ä¿¡æ¯
                try:
                    balance_data = self.exchange.fetch_balance()
                    self._cached_balance = balance_data.get('USDC', {}).get('free', self._cached_balance)
                except Exception as e:
                    self.logger_monitor.debug(f"Failed to fetch balance in heartbeat: {e}")
            
            # ä½¿ç”¨ç¼“å­˜çš„æ•°æ®
            current_price = self._cached_price
            balance = self._cached_balance
            
            # å†™å…¥å¿ƒè·³æ—¥å¿—æ–‡ä»¶
            try:
                with open(self.config.heartbeat_file, 'a', encoding='utf-8') as f:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    f.write(f"{timestamp}: Price=${current_price:.2f}, Position={position_info}, Balance={balance:.2f} USDC\n")
            except Exception as e:
                self.logger_monitor.debug(f"Failed to write heartbeat file: {e}")
            
            # è¾“å‡ºå¿ƒè·³ä¿¡æ¯
            self.logger_monitor.info("ğŸ’“ Heartbeat: %s | Position=%s | Balance=%.2f USDC | Signals=%d | Price=$%.2f",
                                     datetime.now().strftime("%H:%M:%S"), 
                                     position_info, balance, len(self.signal_history), current_price)
            
            # æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ˆä»…åœ¨è·å–æ–°æ•°æ®æ—¶æ£€æŸ¥ï¼‰
            if self._heartbeat_count % 3 == 1:
                if current_price == 0:
                    self.logger_monitor.warning("âš ï¸ Price data unavailable")
                
                if balance < self.config.min_amount_usdc and not position:
                    self.logger_monitor.warning(f"âš ï¸ Low balance: {balance:.2f} USDC")
                
        except Exception as e:
            self.logger_monitor.error(f"Heartbeat error: {e}")
            # ç¡®ä¿å¿ƒè·³ä¸ä¼šå› ä¸ºé”™è¯¯è€Œåœæ­¢
            try:
                with open(self.config.heartbeat_file, 'a', encoding='utf-8') as f:
                    f.write(f"{datetime.now()}: HEARTBEAT ERROR - {str(e)}\n")
            except:
                pass  # å¿½ç•¥æ–‡ä»¶å†™å…¥é”™è¯¯

    def heartbeat_loop(self):
        """Heartbeat loop method"""
        while True:
            try:
                self.heartbeat()
                time.sleep(self.config.heartbeat_interval)
            except Exception as e:
                self.logger_system.error(f"Heartbeat loop error: {e}")
                time.sleep(self.config.heartbeat_interval)

    def backtest_from_file(self, file_path: str):
        """Improved backtest implementation, include full simulation logic and P&L calculation - Optimization 6: Add PF and max DD"""
        try:
            df = pd.read_csv(file_path)
            # FIXED: Medium 11 - Validate columns
            required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_cols):
                raise ValueError(f"CSV missing required columns: {required_cols}")
            if len(df) < 20:
                self.logger_system.warning(f"Backtest data insufficient ({len(df)} rows), suggest at least 20 rows")
                return
            
            # FIXED: High 6 - Add leverage and fees to pnl
            leverage = self.config.leverage
            fee = self.config.fee_rate
            
            # Calculate technical indicators
            df = self.calculate_technical_indicators(df)
            
            signals = []
            trades = []
            total_pnl = 0.0
            wins = 0
            losses = 0
            peak_balance = 10000.0  # Initial balance
            max_drawdown = 0.0
            current_balance = peak_balance
            
            self.logger_system.info(f"Starting backtest, data rows: {len(df)}")
            
            for i, row in df.iterrows():
                if i < 14:  # Need sufficient historical data for indicator calculation
                    continue
                
                # Build more complete price data
                price_data = {
                    'price': row['close'],
                    'timestamp': datetime.now().isoformat(),
                    'multi_tf_data': {
                        '1d': df.iloc[max(0, i-10):i+1].copy(),
                        '4h': df.iloc[max(0, i-40):i+1].copy(),
                        '15m': df.iloc[max(0, i-20):i+1].copy()
                    },
                    'amplitude': {
                        'expected_rr_range': (row['high'] - row['low']) * 2,
                        'daily_range': row['high'] - row['low']
                    },
                    'technical_data': {
                        'atr': row.get('atr', (row['high'] - row['low']) * 0.02),
                        'rsi': row.get('rsi', 50),
                        'ema_20': row.get('ema_20', row['close']),
                        'ema_50': row.get('ema_50', row['close'])
                    },
                    'key_levels': {},  # Simplified for backtest
                    'structures_summary': {}  # Simplified
                }
                
                # Use rule-based signal generation (avoid real AI call)
                signal = self._generate_rule_based_signal(price_data, df.iloc[max(0, i-14):i+1])
                signals.append(signal)
                
                # Simulate trade execution
                if signal['signal'] in ['BUY', 'SELL'] and i + 5 < len(df):  # Ensure sufficient subsequent data
                    trade_result = self._simulate_trade_execution(signal, df.iloc[i:i+6], i)
                    if trade_result:
                        trades.append(trade_result)
                        total_pnl += trade_result['pnl']
                        current_balance += trade_result['pnl']
                        peak_balance = max(peak_balance, current_balance)
                        drawdown = (peak_balance - current_balance) / peak_balance
                        max_drawdown = max(max_drawdown, drawdown)
                        if trade_result['pnl'] > 0:
                            wins += 1
                        else:
                            losses += 1
            
            # Calculate backtest stats - Optimization 6
            num_trades = len(trades)
            win_rate = wins / num_trades if num_trades > 0 else 0
            avg_win = sum(t['pnl'] for t in trades if t['pnl'] > 0) / wins if wins > 0 else 0
            avg_loss = sum(t['pnl'] for t in trades if t['pnl'] < 0) / losses if losses > 0 else 0
            profit_factor = abs(avg_win * wins / (avg_loss * losses)) if losses > 0 and avg_loss != 0 else float('inf')
            
            self.logger_system.info(f"=== Backtest Results ===")
            self.logger_system.info(f"Total trades: {num_trades}")
            self.logger_system.info(f"Win rate: {win_rate:.2%} ({wins} wins/{losses} losses)")
            self.logger_system.info(f"Total PnL: {total_pnl:.4f} USD")
            self.logger_system.info(f"Average win: {avg_win:.4f} USD")
            self.logger_system.info(f"Average loss: {avg_loss:.4f} USD")
            self.logger_system.info(f"Profit factor (PF): {profit_factor:.2f}")
            self.logger_system.info(f"Max drawdown: {max_drawdown*100:.2f}%")
            self.logger_system.info(f"Signal distribution: {dict(pd.Series([s['signal'] for s in signals]).value_counts())}")
            
        except Exception as e:
            self.logger_system.exception(f"Backtest failed: {e}")

    def _simulate_trade_execution(self, signal: Dict[str, Any], future_data: pd.DataFrame, entry_index: int) -> Optional[Dict[str, Any]]:
        """Simulate trade execution and P&L calculation - Optimization 6: Add PF calculation post-trade"""
        try:
            entry_price = signal.get('entry_price', future_data.iloc[0]['close'])
            stop_loss = signal['stop_loss']
            take_profit = signal['take_profit']
            side = signal['signal']
            
            # Simulate slippage
            slippage = 0.001
            if side == 'BUY':
                actual_entry = entry_price * (1 + slippage)
            else:
                actual_entry = entry_price * (1 - slippage)
            
            # FIXED: High 5 - Correct PnL calculation and leverage fees
            amount = self.config.amount
            leverage = self.config.leverage
            # Fee based on notional value: amount * entry_price * leverage * fee_rate * 2 (open + close)
            fee_cost = amount * actual_entry * leverage * self.config.fee_rate * 2
            
            # Check subsequent price movement
            for i, row in future_data.iloc[1:].iterrows():
                high = row['high']
                low = row['low']
                close = row['close']
                
                # Check stop loss/take profit trigger
                if side == 'BUY':
                    if low <= stop_loss:
                        # Stop loss triggered
                        exit_price = stop_loss * (1 - slippage)  # Slippage
                        # Correct PnL formula: (exit_price - entry_price) * amount * leverage - fees
                        pnl = (exit_price - actual_entry) * amount * leverage - fee_cost
                        return {
                            'entry_index': entry_index,
                            'entry_price': actual_entry,
                            'exit_price': exit_price,
                            'side': side,
                            'pnl': pnl,
                            'exit_reason': 'stop_loss',
                            'bars_held': i - future_data.index[0]
                        }
                    elif high >= take_profit:
                        # Take profit triggered
                        exit_price = take_profit * (1 - slippage)
                        pnl = (exit_price - actual_entry) * amount * leverage - fee_cost
                        return {
                            'entry_index': entry_index,
                            'entry_price': actual_entry,
                            'exit_price': exit_price,
                            'side': side,
                            'pnl': pnl,
                            'exit_reason': 'take_profit',
                            'bars_held': i - future_data.index[0]
                        }
                else:  # SELL
                    if high >= stop_loss:
                        # Stop loss triggered
                        exit_price = stop_loss * (1 + slippage)
                        # For SELL: (entry_price - exit_price) * amount * leverage - fees
                        pnl = (actual_entry - exit_price) * amount * leverage - fee_cost
                        return {
                            'entry_index': entry_index,
                            'entry_price': actual_entry,
                            'exit_price': exit_price,
                            'side': side,
                            'pnl': pnl,
                            'exit_reason': 'stop_loss',
                            'bars_held': i - future_data.index[0]
                        }
                    elif low <= take_profit:
                        # Take profit triggered
                        exit_price = take_profit * (1 + slippage)
                        pnl = (actual_entry - exit_price) * amount * leverage - fee_cost
                        return {
                            'entry_index': entry_index,
                            'entry_price': actual_entry,
                            'exit_price': exit_price,
                            'side': side,
                            'pnl': pnl,
                            'exit_reason': 'take_profit',
                            'bars_held': i - future_data.index[0]
                        }
            
            # If no stop loss/take profit triggered, close at last price
            final_price = future_data.iloc[-1]['close']
            if side == 'BUY':
                exit_price = final_price * (1 - slippage)
                pnl = (exit_price - actual_entry) * amount * leverage - fee_cost
            else:
                exit_price = final_price * (1 + slippage)
                pnl = (actual_entry - exit_price) * amount * leverage - fee_cost
            
            return {
                'entry_index': entry_index,
                'entry_price': actual_entry,
                'exit_price': exit_price,
                'side': side,
                'pnl': pnl,
                'exit_reason': 'timeout',
                'bars_held': len(future_data) - 1
            }
            
        except Exception as e:
            self.logger_trading.warning(f"Trade simulation failed: {e}")
            return None

    def _generate_rule_based_signal(self, price_data, recent_df):
        """Generate signal based on rules for backtest"""
        # Simple rule example: RSI overbought/oversold + trend
        rsi = price_data['technical_data'].get('rsi', 50)
        if rsi > 70:
            signal = 'SELL'
            reason = 'RSI overbought'
        elif rsi < 30:
            signal = 'BUY'
            reason = 'RSI oversold'
        else:
            signal = 'HOLD'
            reason = 'Neutral RSI'
        
        current = price_data['price']
        stop_loss = current * 0.98 if signal == 'BUY' else current * 1.02
        take_profit = current * 1.02 if signal == 'BUY' else current * 0.98
        
        return {
            'signal': signal,
            'reason': reason,
            'stop_loss': stop_loss,
            'take_profit': take_profit,
            'confidence': 'MEDIUM',
            'entry_price': current
        }

    def start_dynamic_sl_tp_monitor(self):
        def monitor_sl_tp():
            while True:
                position = self.position_store.get()
                if position:
                    # Fetch current price and check SL/TP (simplified)
                    ticker = self.safe_fetch_ticker(self.exchange, config.symbol)
                    current_price = ticker['last']
                    side = position['side']
                    if side == 'buy':
                        if current_price <= position['liquidation_price']:
                            # Close position on SL
                            self.safe_create_order(self.exchange, config.symbol, 'sell', position['size'], {'reduce_only': True})
                            self.position_store.clear()
                            self.logger_trading.info("Stop loss triggered and position closed")
                    # Similar for TP and sell side
                time.sleep(30)  # Check every 30s
        self.sl_tp_monitor_thread = threading.Thread(target=monitor_sl_tp, daemon=True)
        self.sl_tp_monitor_thread.start()

    def trading_bot(self, activated_level: Optional[str] = None, is_scheduled: bool = False):
        """Main trade logic execution method - FIXED: Kill Zone 4 - å¯é…ç½®è¿‡æ»¤ + æ•°æ®å®Œæ•´æ€§æ£€æŸ¥"""
        if not self.trade_lock.acquire(blocking=False):
            self.logger_system.warning("Trade in progress, skip this execution")
            return
        
        try:
            start_time = time.time()
            self.logger_system.info("=== Start trade analysis ===")
            
            # FIXED: Kill Zone 5 - é…ç½®åŒ–è¿‡æ»¤ï¼Œå¦‚æœç¦ç”¨åˆ™è­¦å‘Šä½†ç»§ç»­
            if self.config.enable_kill_zone:
                now_utc = datetime.now(timezone.utc).hour
                if not (self.config.kill_zone_start_utc <= now_utc <= self.config.kill_zone_end_utc):
                    self.logger_system.info(f"Outside Kill Zone (UTC {now_utc}), skipping trade")
                    return
                else:
                    self.logger_system.debug(f"Inside Kill Zone (UTC {now_utc})")
            else:
                self.logger_system.warning("Kill Zone disabled - proceeding with analysis (test mode)")
            
            # Get price data
            price_data = self._fetch_and_update_data(activated_level)
            if not price_data:
                self.logger_system.error("Unable to get price data, skip this trade")
                return
            
            # FIXED: Data 3 - æ£€æŸ¥å¤š TF æ•°æ®å®Œæ•´æ€§ï¼ˆè‡³å°‘ 70% TF æœ‰æ•°æ®ï¼‰
            multi_tf_data = price_data.get('multi_tf_data', {})
            valid_tfs = sum(1 for df in multi_tf_data.values() if len(df) >= 20)
            if valid_tfs < len(self.config.timeframes) * 0.7:
                self.logger_system.warning(f"Insufficient multi-TF data (valid: {valid_tfs}/{len(self.config.timeframes)}), skipping")
                return
            
            # æ£€æŸ¥ä»·æ ¼æ¿€æ´»çŠ¶æ€
            is_activated = price_data.get('is_activated', False)
            activated_level_from_data = price_data.get('activated_level', activated_level)
            
            self.logger_system.info(f"ä»·æ ¼æ¿€æ´»çŠ¶æ€: {'âœ… å·²æ¿€æ´»' if is_activated else 'âŒ æœªæ¿€æ´»'}")
            if activated_level_from_data:
                self.logger_system.info(f"æ¿€æ´»æ°´å¹³: {activated_level_from_data}")
            
            # New: Apply intraday momentum filter
            if not self.intraday_momentum_filter(price_data):
                self.logger_system.info("Intraday momentum filter failed, skipping trade")
                return
            
            # If scheduled task, check if last signal copy exists
            if is_scheduled:
                # If last signal copy exists, directly use
                if self.last_scheduled_signal:
                    self.logger_system.info("Use last scheduled task signal copy for trade execution")
                    self.execute_trade(self.last_scheduled_signal, price_data, None)  # Fix: Pass None as activated_level
                    execution_time = time.time() - start_time
                    self.logger_system.info(f"=== Trade analysis completed (time: {execution_time:.2f}s) ===")
                    return
            
            # æ™ºèƒ½ä¿¡å·ç”Ÿæˆï¼šæ ¹æ®æ¿€æ´»çŠ¶æ€é€‰æ‹©ç­–ç•¥
            if is_activated:
                # ä»·æ ¼å·²æ¿€æ´»ï¼Œä¼˜å…ˆä½¿ç”¨DeepSeek AIåˆ†æ
                self.logger_system.info("ğŸ¤– ä»·æ ¼å·²æ¿€æ´»ï¼Œä½¿ç”¨DeepSeek AIè¿›è¡Œæ·±åº¦åˆ†æ")
                signal_data = self.analyze_with_deepseek(price_data, activated_level_from_data)
                if not signal_data:
                    self.logger_system.warning("DeepSeekåˆ†æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ä¿¡å·ç”Ÿæˆ")
                    signal_data = self._generate_fallback_signal(price_data, activated_level_from_data)
            else:
                # ä»·æ ¼æœªæ¿€æ´»ï¼Œç›´æ¥ä½¿ç”¨å¤‡ç”¨ä¿¡å·ï¼ˆåŸºäºæŠ€æœ¯æŒ‡æ ‡ï¼‰
                self.logger_system.info("ğŸ“Š ä»·æ ¼æœªæ¿€æ´»ï¼Œä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡å¤‡ç”¨ä¿¡å·")
                signal_data = self._generate_fallback_signal(price_data, activated_level_from_data)
            
            if not signal_data:
                self.logger_system.error("æ— æ³•ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼Œè·³è¿‡æœ¬æ¬¡äº¤æ˜“")
                return
            
            # If scheduled task, save signal copy
            if is_scheduled:
                self.last_scheduled_signal = signal_data.copy()
                self.logger_system.info("Scheduled task signal copy saved")
            
            # Execute trade
            self.execute_trade(signal_data, price_data, activated_level)
            
            execution_time = time.time() - start_time
            self.logger_system.info(f"=== Trade analysis completed (time: {execution_time:.2f}s) ===")
            
        except Exception as e:
            self.logger_system.error(f"Trade execution error: {e}")
        finally:
            self.trade_lock.release()

def job_wrapper(bot, func, *args, **kwargs):
    # If func is bound method, call directly; otherwise pass bot as first parameter
    if hasattr(func, '__self__'):
        # If trading_bot method, add is_scheduled=True parameter
        if func.__name__ == 'trading_bot':
            bot.executor.submit(func, is_scheduled=True, *args, **kwargs)
        else:
            bot.executor.submit(func, *args, **kwargs)
    else:
        # If trading_bot function, add is_scheduled=True parameter
        if func.__name__ == 'trading_bot':
            bot.executor.submit(func, bot, is_scheduled=True, *args, **kwargs)
        else:
            bot.executor.submit(func, bot, *args, **kwargs)

def main():
    # åˆå§‹åŒ–å…¨å±€é…ç½®å’Œå®¢æˆ·ç«¯
    initialize_globals()
    
    # FIXED: Medium 7 - Env vars conditional on sim mode
    required_env_vars = ['DEEPSEEK_API_KEY']
    if not config.simulation_mode:
        required_env_vars += ['HYPERLIQUID_WALLET_ADDRESS', 'HYPERLIQUID_PRIVATE_KEY']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    if missing_vars:
        system_logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
        return

    bot = TradingBot(config, exchange)
    bot.load_signal_history()
    system_logger.info("BTC/USD Hyperliquid SMC/ICT Auto Trading Bot Started Successfully!")
    system_logger.info("Institutional order flow analysis: Weekly liquidity > Daily liquidity > Order blocks > Volume distribution > Technical levels")
    system_logger.info(f"Key level priority: {', '.join(config.liquidity_priority)}")
    system_logger.info("Key level activation monitoring + Risk management + Dynamic position enabled")
    system_logger.info(f"Heartbeat enabled (interval: {config.heartbeat_interval}s), Log: {config.heartbeat_file}")
    system_logger.warning("Live trading mode, operate cautiously!" if not config.simulation_mode else "Simulation mode activated")
    system_logger.info(f"Primary timeframe: {config.primary_timeframe}")

    # New: Log new features
    system_logger.info(f"Multi-timeframe alignment: Higher TF bias={config.higher_tf_bias_tf}, Lower TF entry={config.lower_tf_entry_tf}")
    system_logger.info(f"Confirmation signals: Volume>{config.volume_confirmation_threshold}x MA, FVG stacking>={config.fvg_stack_threshold}, Fresh zone interactions<={config.max_zone_interactions}")

    # Fixed: Check if backtest_file exists
    if config.backtest_file and os.path.exists(config.backtest_file):
        bot.backtest_from_file(config.backtest_file)

    if not bot.setup_exchange():
        system_logger.error("Exchange initialization failed, exit program")
        return

    # Fixed: Initial trading_bot call for startup signal check
    bot.trading_bot()

    monitor_thread = threading.Thread(target=bot.price_monitor_loop, daemon=True)
    monitor_thread.start()
    system_logger.info("Price monitoring thread started (every 3 minutes)")

    heartbeat_thread = threading.Thread(target=bot.heartbeat_loop, daemon=True)
    heartbeat_thread.start()
    system_logger.info("Heartbeat thread started")

    # Start dynamic stop profit/loss monitoring thread
    bot.start_dynamic_sl_tp_monitor()
    system_logger.info("Dynamic stop profit/loss monitoring thread started (check every 30s)")

    schedule.every(5).minutes.do(job_wrapper, bot, bot.trading_bot)  # Changed to 5min for aggressive
    system_logger.info("Scheduled execution frequency: Every 5 minutes")

    try:
        while True:
            try:  # FIXED: Medium 6 - Health check on schedule
                schedule.run_pending()
            except Exception as sched_e:
                system_logger.error(f"Schedule error: {sched_e}")
            time.sleep(1)
    except KeyboardInterrupt:
        system_logger.info("Received interrupt signal, gracefully exiting...")
    except Exception as e:
        system_logger.error(f"Main loop unexpected error: {e}")
    finally:
        try:
            system_logger.info("Cleaning resources...")
            bot.save_signal_history()
            bot.executor.shutdown(wait=True)
            # FIXED: Medium 9 - Join threads
            if 'monitor_thread' in locals():
                monitor_thread.join(timeout=5)
            if 'heartbeat_thread' in locals():
                heartbeat_thread.join(timeout=5)
            system_logger.info("Resource cleanup completed")
        except Exception as e:
            system_logger.error(f"Cleanup error: {e}")

if __name__ == "__main__":
    main()